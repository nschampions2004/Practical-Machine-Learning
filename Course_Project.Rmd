---
title: "Machine Learning Project"
author: "Kyle"
date: "July 22, 2016"
output: html_document
---
#Step 1: Reading the Data
Download and read the data into R.  
```{r}
library(caret); library(ggplot2); library(rattle); library(parallel); library(doParallel)

#reading in the data
training_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("test_data.csv")){
  download.file(test_url, destfile = "test_data.csv")}
if(!file.exists("training_data.csv")){
  download.file(training_url, destfile = "training_data.csv")}
training <- read.csv("training_data.csv")
testing <- read.csv("test_data.csv")
```
#Step 2: Clean the Data
Remove the columns that are completely filled with NA's.  Take out the columns that have low variances.  Take out the first six columns that have little to do with aiding prediction.  
```{r}
#exploratory data analysis
#there are a ton of columns with na's, time to shrink this data set
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]
#cleaning the training set
zerovar <- nearZeroVar(training, saveMetrics = FALSE)
training <- training[ , -zerovar]
training <- training[, -c(1,2,3,4,5,6)]
```
#Step 3: Split the training set into 60% training, 40% validation.
```{r}
#split the training data into a validation set and training set at the 0.6 level
inTrain <- createDataPartition(training$classe, p = 0.6, list = FALSE)
training <- training[inTrain, ]
checker <- training[-inTrain, ]
```
#Step 4: Make clusters for Parallel Processing
Utitlizing parallel processing will speed up the process of using random forests.  Additionally, making k-fold cross validation will help with determining the accuracy of our prediction and reduction in variability of our prediction, 
```{r}
#making clusters for parallel processing
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
#configuring trainControl object
fitControl <- trainControl(method = "cv", number = 5, allowParallel = TRUE)
```
#Step 5a: Build an LDA model
```{r}
model_lda <- train(classe ~. , data = training, method = "lda")
```
#Step 5b: Build the Random Forest Model.
Builing the random forest model, although painstakingly slow, yields the best accuracy.  
```{r}
#model build
model_rf <- train(classe ~ ., data = training, trControl = fitControl)

stopCluster(cluster)
```
#Step 6: Check the Random Forest Model on the Checker validation Set.
Now that we have a model, we utilize that model to check out validation set 'checker'.  
```{r}
predict_lda_checker <- predict(model_lda, checker)
predict_rf_checker <- predict(model_rf, checker)
print(c(confusionMatrix(predict_rf_checker, checker$classe),
        confusionMatrix(predict_lda_checker, checker$classe)))
```
Noting a strong finish, we use the model on the 20 data points located in the test set.  

#Step 7: Use the Random Forest Model to predict on the Testing Set since it has the higher accuracy.  
```{r}
print(predict(model_rf, testing))
```



